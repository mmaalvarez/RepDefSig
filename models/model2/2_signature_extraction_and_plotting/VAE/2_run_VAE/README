Mischan's autoencoder
---------------------
	scale the CI-permuted coefficients matrices to [-1, +1] (e.g. python minmax scaler) because final decoding layer uses tanh as activation

code
	from github.com/lehner-lab/RDGVassociation/tree/main/somatic_component_extraction

	1 VAE code with train/test setting, and 1 without

	need to optimize the hyperparameters

	environment Mischan used is saved in the docker image (downloaded in singularity_container/)

	all explained in github's readme; relevant excerpt here:

		### Extractions of Variational Autoencoder derived Components
		VAE_tensorflow1.py:
			Running Variational Autoencoder with dataset split (90 % training and 10% test) to find optimal parameters. Recommended to be run in Singularity environment. Example:

			singularity exec tensorflow1.15.5_gpu_jupyter_moredependencies-v1.simg python VAE_tensorflow1.py --learning_rate 0.0005 --batch_size 200 --epochs 200 --num_components 14 --dataset_training 'TCGA_Hartwig_PCAWG_least45of56_14832samples_90split_balanced.txt' --dataset_test 'TCGA_Hartwig_PCAWG_least45of56_14832samples_10split_balanced.txt' --kappa 0.5 --depth 1
		
		VAE_tensorflow1_nosplit_alldata.py:
			Running on complete dataset after finding optimal parameters. Example:

			singularity exec tensorflow1.15.5_gpu_jupyter_moredependencies-v1.simg python VAE_tensorflow1_nosplit_alldata.py --learning_rate 0.0005 --batch_size 200 --epochs 200 --num_components 14 --dataset_training 'TCGA_Hartwig_PCAWG_least45of56_14832samples_nosplit_balanced.txt' --kappa 0.5 --depth 1

		### Final Set of Components
		Components_overview.R:
			Plotting heatmap with ICs and VAE-derived components

	remove some code in the end which is used for estimating some KPIs specific for Mischan's case ("golden ICs" stuff) 

output
	mean_encoded layer of the VAE (all positive values because of RelU) is equivalent to the exposures from the NMF
	
	"weights is not so trivial because there is also the bias term in the neural net, so you can't easily compare it. This is why we used Pearson correlations. What could be done (but we haven't) is to train a decision tree or random forest and use SHAP to get some feature importance [Shapley values] for each VAE "signature", but it would be mathematically of course not the same like the weights from the NMF"
